
Azizha Zeinita

=== Ensemble Models - Logistic Regression, Classification Trees, LDA, QDA, KNN, SVM, Naive Bayes ===

1. Use the training and test samples for the Diabetes data set that you used for the Logistic Regression analysis.
```{r}
Diabetes = read.csv("/Users/azizhazeinita/Documents/S2 Uchicago/MScA/Winter 2022 - 2nd Quarter/Data Mining Principles/Assignment 6 - Data Mining Principles/diabetes_preprocessed_nodummies.csv")
```

1.1. One-hot encoding
```{r}
library(caret)
dummy <- dummyVars(" ~ .", data=Diabetes) #define one-hot encoding function
df_dummy <- data.frame(predict(dummy, newdata=Diabetes)) #perform one-hot encoding on data frame

```


```{r}
df <- df_dummy[c('raceAfricanAmerican','raceAsian','raceHispanic', 'gender', 'age','time_in_hospital', 'num_lab_procedures','num_procedures','num_medications','number_outpatient', 'number_inpatient', 'diag_1Diabetes', 'diag_1Respiratory', 'number_diagnoses', 'max_glu_serumNormal', 'max_glu_serumNot.tested','A1CresultAbnormal', 'metforminUp', 'chlorpropamideNo', 'glipizideDown', 'pioglitazoneSteady', 'rosiglitazoneUp', 'acarboseUp','troglitazoneNo', 'insulinDown', 'glyburide.metforminUp', 'glipizide.metforminSteady', 'readmitted')]
```


1.2. Set test and training dataset
```{r}
set.seed(123)
s1=sample(1:nrow(df),nrow(df)*0.7,replace=FALSE)
train=(df[s1,])
test=(df[-s1,])
```

2. Use the Train data set to build K-Nearest Neighbors, SVMs, and Naïve Bayes to predict the Readmitted Variable.


2.1. KNN
```{r}
require(class)
knn_1 <- knn(train[1:27],test[1:27],df[s1,28],k=1)
knn_2 <- knn(train[1:27],test[1:27],df[s1,28],k=2)
knn_3 <- knn(train[1:27],test[1:27],df[s1,28],k=3)
knn_4 <- knn(train[1:27],test[1:27],df[s1,28],k=4)
knn_5 <- knn(train[1:27],test[1:27],df[s1,28],k=5)

```

```{r}
#KNN Prediction
knn_predict <- knn(train[1:27],test[1:27],df[s1,28], knn_5, k=5)

#Confussion Matrix
conf_1 <- table(df[-s1,28],knn_1)
conf_2 <- table(df[-s1,28],knn_2)
conf_3 <- table(df[-s1,28],knn_3)
conf_4 <- table(df[-s1,28],knn_4)
conf_5 <- table(df[-s1,28],knn_5)
#percent_5 <- round(prop.table(table(df[-s1,49],knn_5),1),2)

conf_1
conf_2
conf_3
conf_4
conf_5

#Accuracy
accuracy_1 <- sum(diag(conf_1))/sum(conf_1) * 100
accuracy_2 <- sum(diag(conf_2))/sum(conf_2) * 100
accuracy_3 <- sum(diag(conf_3))/sum(conf_3) * 100
accuracy_4 <- sum(diag(conf_4))/sum(conf_4) * 100
accuracy_5 <- sum(diag(conf_5))/sum(conf_5) * 100

#Plot of Correctness
plot(1:5,c(accuracy_1,accuracy_2,accuracy_3,accuracy_4,accuracy_5),
main="Effectiveness of predicting Readmitted",xlab="K",
ylab="Overall Percent of Readmitted correctly classified",col=2,type="l")

#From the plot below, the best K is 5
```

2.2. SVMs
```{r}
#It's been done in python, and I will use the prediction downloaded from there

svm_pred_train = read.csv("/Users/azizhazeinita/Documents/S2 Uchicago/MScA/Winter 2022 - 2nd Quarter/Data Mining Principles/Assignment 6 - Data Mining Principles/svm_pred_train.csv")
svm_pred_test = read.csv("/Users/azizhazeinita/Documents/S2 Uchicago/MScA/Winter 2022 - 2nd Quarter/Data Mining Principles/Assignment 6 - Data Mining Principles/svm_pred_test.csv")
```

2.3. Naive Bayes
```{r}
library(naivebayes)
train_nb <- data.frame(train)
test_nb <- data.frame(test)
nb <- naive_bayes(as.character(readmitted) ~ ., data = train_nb) 
nb_predict <- predict(nb, test_nb [ , names(test_nb) != "readmitted"])
```

3. Ensemble Models

3.1. Logistic Regression
```{r} 
glm <- glm(readmitted~., data=train, family=binomial (link='logit'))

```


3.2. Classification Trees
```{r} 
library(rpart)
x=rpart(readmitted~., data=train,control=rpart.control(cp=0,minsplit=30,xval=10))

min_xerror <- which.min(x$cptable[,"xerror"])
cp <- x$cptable[min_xerror, "CP"]

class_tree <- rpart(readmitted~., data=train,control=rpart.control(cp=cp,minsplit=30,xval=10))
```

3.3. LDA
```{r} 
library(MASS)
lda=lda(readmitted~., data = train)
```

3.4. QDA
```{r} 
library(MASS)
train2 <- data.frame(train[c(1:23,25,27:28)]) #excluding rank deficiency
qda=qda(readmitted~., data = train2)
```

3.5. Prediction for All of Models
```{r}
#KNN
knn_predict_train <- knn(train[1:27],train[1:27],df[s1,28], knn_5, k=5)
knn_predict_test <- knn(train[1:27],test[1:27],df[s1,28], knn_5, k=5)

#SVM
svm_predict_train <- svm_pred_train
svm_predict_test <- svm_pred_test

#Naive Bayes
nb_predict_train <- predict(nb, train_nb [ , names(train_nb) != "readmitted"], type="class")
nb_predict_test <- predict(nb, test_nb [ , names(test_nb) != "readmitted"], type="class")

#Linear Regression
lr_predict_train <- predict.glm(glm, newdata=train, type = "response")
lr_predict_test <- predict(glm, newdata=test, type = "response")
lr_predict_train <- ifelse(lr_predict_train >0.5, 1, 0)
lr_predict_test <- ifelse(lr_predict_test >0.5, 1, 0)

#Classification Trees
ct_predict_train <- predict(class_tree, data=train, type="vector")
ct_predict_test <- predict(class_tree, newdata=test, type="vector")
ct_predict_train <- ifelse(ct_predict_train >0.5, 1, 0)
ct_predict_test <- ifelse(ct_predict_test >0.5, 1, 0)

#LDA
lda_predict_train <- predict(lda, newdata = train)$class
lda_predict_test <- predict(lda, newdata = test)$class

#QDA
qda_predict_train <- predict(qda, newdata = train)$class
qda_predict_test <- predict(qda, newdata = test)$class

```

4. Build another model across all 7 models that you have built thus far – Logisitc, Classification Trees, LDA, QDA, KNN, SVM, and Naïve Bayes for predicting the "Readmitted" variable.
```{r}
svm_df_train <- svm_predict_train
svm_df_train[1] <- NULL
svm_df_train <- lapply(svm_df_train, as.numeric)

svm_df_test <- svm_predict_test
svm_df_test[1] <- NULL
svm_df_test <- lapply(svm_df_test, as.numeric)

df_ensemble_train <- data.frame(knn_predict_train, nb_predict_train, lr_predict_train, ct_predict_train, lda_predict_train, qda_predict_train, svm_df_train)

df_ensemble_train$knn_predict_train <- as.numeric(levels(df_ensemble_train$knn_predict_train))[df_ensemble_train$knn_predict_train]
df_ensemble_train$nb_predict_train <- as.numeric(levels(df_ensemble_train$nb_predict_train))[df_ensemble_train$nb_predict_train]
df_ensemble_train$lda_predict_train <- as.numeric(levels(df_ensemble_train$lda_predict_train))[df_ensemble_train$lda_predict_train]
df_ensemble_train$qda_predict_train <- as.numeric(levels(df_ensemble_train$qda_predict_train))[df_ensemble_train$qda_predict_train]

df_ensemble_test <- data.frame(knn_predict_test, nb_predict_test, lr_predict_test, ct_predict_test, lda_predict_test, qda_predict_test, svm_df_test)

df_ensemble_test$knn_predict_test <- as.numeric(levels(df_ensemble_test$knn_predict_test))[df_ensemble_test$knn_predict_test]
df_ensemble_test$nb_predict_test <- as.numeric(levels(df_ensemble_test$nb_predict_test))[df_ensemble_test$nb_predict_test]
df_ensemble_test$lda_predict_test <- as.numeric(levels(df_ensemble_test$lda_predict_test))[df_ensemble_test$lda_predict_test]
df_ensemble_test$qda_predict_test <- as.numeric(levels(df_ensemble_test$qda_predict_test))[df_ensemble_test$qda_predict_test]

          
#The majority vote 
df_ensemble_train$yes_sum <- (df_ensemble_train$knn_predict_train + df_ensemble_train$nb_predict_train +   df_ensemble_train$lr_predict_train + df_ensemble_train$ct_predict_train + df_ensemble_train$lda_predict_train + df_ensemble_train$qda_predict_train + df_ensemble_train$X0)

df_ensemble_train$ensemble <- (ifelse(df_ensemble_train$yes_sum >= 3, 'Yes', 'No'))
df_ensemble_train$ensemble10 <- (ifelse(df_ensemble_train$ensemble == 'Yes', 1, 0))

df_ensemble_test$yes_sum <- (df_ensemble_test$knn_predict_test + df_ensemble_test$nb_predict_test +   df_ensemble_test$lr_predict_test + df_ensemble_test$ct_predict_test + df_ensemble_test$lda_predict_test + df_ensemble_test$qda_predict_test + df_ensemble_test$X0)

df_ensemble_test$ensemble <- (ifelse(df_ensemble_test$yes_sum >= 3, 'Yes', 'No'))                 
df_ensemble_test$ensemble10 <- (ifelse(df_ensemble_test$ensemble == 'Yes', 1, 0)) 

df_ensemble_train
df_ensemble_test
```

3.7. Confusion Matrix for Ensemble Prediction
```{r}
#KNN
print("KNN-Ensemble Confusion Matrix Train Set")
cm_knn_train <- confusionMatrix(as.factor(knn_predict_train), as.factor(df_ensemble_train$ensemble10))
cm_knn_train

print("KNN-Ensemble Confusion Matrix Test Set")
cm_knn_test <- confusionMatrix(as.factor(knn_predict_test), as.factor(df_ensemble_test$ensemble10))
cm_knn_test

#SVM
print("SVM-Ensemble Confusion Matrix Train Set")
cm_cvm_train <- confusionMatrix(as.factor(df_ensemble_train$X0), as.factor(df_ensemble_train$ensemble10))
cm_cvm_train

print("KNN-Ensemble Confusion Matrix Test Set")
cm_cvm_test <- confusionMatrix(as.factor(df_ensemble_test$X0), as.factor(df_ensemble_test$ensemble10))
cm_cvm_test

#Naive Bayes
print("Naive Bayes-Ensemble Confusion Matrix Train Set")
cm_nb_train <- confusionMatrix(as.factor(nb_predict_train), as.factor(df_ensemble_train$ensemble10))
cm_nb_train

print("Naive Bayes-Ensemble Confusion Matrix Test Set")
cm_nb_test <- confusionMatrix(as.factor(nb_predict_test), as.factor(df_ensemble_test$ensemble10))
cm_nb_test

#Linear Regression
print("Linear Regression-Ensemble Confusion Matrix Train Set")
cm_lr_train <- confusionMatrix(as.factor(lr_predict_train), as.factor(df_ensemble_train$ensemble10))
cm_lr_train

print("NLinear Regression-Ensemble Confusion Matrix Test Set")
cm_lr_test <- confusionMatrix(as.factor(lr_predict_test), as.factor(df_ensemble_test$ensemble10))
cm_lr_test

#Classification Trees
print("Classification Trees-Ensemble Confusion Matrix Train Set")
cm_ct_train <- confusionMatrix(as.factor(ct_predict_train), as.factor(df_ensemble_train$ensemble10))
cm_ct_train

print("Classification Trees-Ensemble Confusion Matrix Test Set")
cm_ct_test <- confusionMatrix(as.factor(ct_predict_test), as.factor(df_ensemble_test$ensemble10))
cm_ct_test

#LDA
print("LDA-Ensemble Confusion Matrix Train Set")
cm_lda_train <- confusionMatrix(as.factor(lda_predict_train), as.factor(df_ensemble_train$ensemble10))
cm_lda_train

print("LDA-Ensemble Confusion Matrix Test Set")
cm_lda_test <- confusionMatrix(as.factor(lda_predict_test), as.factor(df_ensemble_test$ensemble10))
cm_lda_test

#QDA
print("QDA-Ensemble Confusion Matrix Train Set")
cm_qda_train <- confusionMatrix(as.factor(qda_predict_train), as.factor(df_ensemble_train$ensemble10))
cm_qda_train

print("QDA-Ensemble Confusion Matrix Test Set")
cm_qda_test <- confusionMatrix(as.factor(qda_predict_test), as.factor(df_ensemble_test$ensemble10))
cm_qda_test

#train[c(1:23,25,27:28)]
```

```{r}
Ensemble <- data.frame(Model = c('KNN', 'SVM', 'Naive Bayes', 'Linear Regression', 'Classification Trees', 'LDA', 'QDA'))

#Overall Accuracys
Ensemble$Overal_Accuracy_Train <- c(cm_knn_train$overall[1], cm_cvm_train$overall[1], cm_nb_train$overall[1], cm_lr_train$overall[1], cm_ct_train$overall[1], cm_lda_train$overall[1], cm_qda_train$overall[1])

Ensemble$Overal_Accuracy_Test <- c(cm_knn_test$overall[1], cm_cvm_test$overall[1], cm_nb_test$overall[1], cm_lr_test$overall[1], cm_ct_test$overall[1], cm_lda_test$overall[1], cm_qda_test$overall[1])

#Accuracy of 00
Ensemble$Accuracy_00_Train <- c(cm_knn_train$byClass[3], cm_cvm_train$byClass[3], cm_nb_train$byClass[3], cm_lr_train$byClass[3], cm_ct_train$byClass[3], cm_lda_train$byClass[3], cm_qda_train$byClass[3])

Ensemble$Accuracy_00_Test <- c(cm_knn_test$byClass[3], cm_cvm_test$byClass[3], cm_nb_test$byClass[3], cm_lr_test$byClass[3], cm_ct_test$byClass[3], cm_lda_test$byClass[3], cm_qda_test$byClass[3])

#Accuracy of 11
Ensemble$Accuracy_11_Train <- c(cm_knn_train$byClass[4], cm_cvm_train$byClass[4], cm_nb_train$byClass[4], cm_lr_train$byClass[4], cm_ct_train$byClass[4], cm_lda_train$byClass[4], cm_qda_train$byClass[4])

Ensemble$Accuracy_11_Test <- c(cm_knn_test$byClass[4], cm_cvm_test$byClass[4], cm_nb_test$byClass[4], cm_lr_test$byClass[4], cm_ct_test$byClass[4], cm_lda_test$byClass[4], cm_qda_test$byClass[4])

#Precision
Ensemble$Precision_Train <- c(cm_knn_train$byClass[5], cm_cvm_train$byClass[5], cm_nb_train$byClass[5], cm_lr_train$byClass[5], cm_ct_train$byClass[5], cm_lda_train$byClass[5], cm_qda_train$byClass[5])

Ensemble$Precision_Test <- c(cm_knn_test$byClass[5], cm_cvm_test$byClass[5], cm_nb_test$byClass[5], cm_lr_test$byClass[5], cm_ct_test$byClass[5], cm_lda_test$byClass[5], cm_qda_test$byClass[5])

#Recall
Ensemble$Recall_Train <- c(cm_knn_train$byClass[6], cm_cvm_train$byClass[6], cm_nb_train$byClass[6], cm_lr_train$byClass[6], cm_ct_train$byClass[6], cm_lda_train$byClass[6], cm_qda_train$byClass[6])

Ensemble$Recall_Test <- c(cm_knn_test$byClass[6], cm_cvm_test$byClass[6], cm_nb_test$byClass[6], cm_lr_test$byClass[6], cm_ct_test$byClass[6], cm_lda_test$byClass[6], cm_qda_test$byClass[6])

#F1 Score
Ensemble$F1Score_Train <- c(cm_knn_train$byClass[7], cm_cvm_train$byClass[7], cm_nb_train$byClass[7], cm_lr_train$byClass[7], cm_ct_train$byClass[7], cm_lda_train$byClass[7], cm_qda_train$byClass[7])

Ensemble$F1Score_Test <- c(cm_knn_test$byClass[7], cm_cvm_test$byClass[7], cm_nb_test$byClass[7], cm_lr_test$byClass[7], cm_ct_test$byClass[7], cm_lda_test$byClass[7], cm_qda_test$byClass[7])

Ensemble

```




